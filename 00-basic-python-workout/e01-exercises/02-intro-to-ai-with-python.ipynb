{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS50 Intro to AI with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Artificial Intelligence (AI) covers a range of techniques that appear as sentient behavior by the computer.\n",
    "\n",
    "This course explores:\n",
    "+ [**Search**](#search)\n",
    "    \n",
    "    Finding a solution to a problem, like a navigator app that finds the best route from your origin to the destination, or like playing a game and figuring out the next move.\n",
    "\n",
    "+ **Knowledge**\n",
    "\n",
    "    Representing information and drawing inferences from it.\n",
    "\n",
    "+ **Uncertainty**\n",
    "\n",
    "    Dealing with uncertain events using probability.\n",
    "\n",
    "+ **Optimization**\n",
    "\n",
    "    Finding not only a correct way to solve a problem, but a better &mdash; or the best &mdash; way to solve it.\n",
    "\n",
    "+ **Learning**\n",
    "\n",
    "    Improving performance based on access to data and experience. For example, your email is able to distinguish spam from non-spam mail based on past experience.\n",
    "\n",
    "+ **Neural Networks**\n",
    "\n",
    "    A program structure inspired by the human brain that is able to perform tasks effectively.\n",
    "\n",
    "+ **Language**\n",
    "\n",
    "    Processing natural language, which is produced and understood by humans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Search\n",
    "\n",
    "Search problems involve an agent that is given an initial state and a goal state, and it returns a solution of how to get from the former to the latter.\n",
    "\n",
    "> **Definition: agent**<br><br>An **agent** is an entity that perceives its environment and acts upon that environment.\n",
    "\n",
    "When solving the solution to a maze, the agent is the AI program or the person trying to solve the maze.\n",
    "\n",
    "> **Definition: state**<br><br>A configuration of the agent and its environment.\n",
    "\n",
    "In the maze problem, the state is the position that the AI/person (i.e., the agent), is evaluating at some point in time.\n",
    "\n",
    "> **Definition: initial state**<br><br>The state in which the agent begins.\n",
    "\n",
    "In the maze problem, the initial state would be the position of the start of the maze.\n",
    "\n",
    "> **Definition: actions**<br><br>Choices that can be made in a state.<br>More formally, it can be defined as a function $ \\mathcal{A}ctions(s) $ that returns the set of actions that can be executed in state $ s $.\n",
    "\n",
    "For example, in the 15 tiles problem ([15 puzzle](https://en.wikipedia.org/wiki/15_puzzle)), there are 4 possible actions:\n",
    "  + slide the tile right\n",
    "  + slide the tile left\n",
    "  + slide the tile up\n",
    "  + slide the tile down\n",
    "\n",
    "> **Definition: transition model**<br><br>A description of what state results from performing any applicable action in any state.<br>As a function, it can be defined as $ \\mathcal{R}esult(s, a) $  which returns the state resulting from performing action $ a $ in state $ s $.\n",
    "\n",
    "> **Definition: state space**<br><br>The set of all states reachable from the initial state by any sequence of actions.<br>This is typically represented as a graph, where the nodes are the states and the arrows represent the actions that transition with some particular state to another.\n",
    "\n",
    "![State Space](../images/ds_state_space.png)\n",
    "\n",
    "> **Definition: goal test**<br><br>A way to determine whether a given state is a goal state.\n",
    "\n",
    "In the maze problem, the goal test is checking that the current state matches the exit of the maze.\n",
    "\n",
    "> **Definition: path cost**<br><br>A numerical cost associated with a given path.\n",
    "\n",
    "This is useful for problems with multiple ways of reaching the goal (e.g., driving directions). You will want to use AI to find the solution with the least cost. This is typicaly solved by tagging the arrows in the graph with some number indicating the cost of that action or transition. In many cases, such as the 15-tiles problem, the cost of the action will be one, so the problem for the AI program to solve would be to find the set of actions with a minimum number of transitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Solving Search Problems\n",
    "\n",
    "> **Definition: solution**<br><br>A sequence of actions that lead from the initial state to a goal state.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Charateristics of a search problem\n",
    "\n",
    "Search problems are characterized by:\n",
    "\n",
    "+ **initial state**: the place where we begin the search\n",
    "+ **actions**: the set of actions that we can take on any given state\n",
    "+ **transition model**: some way of defining what happens when we are in one state and take an action that lead us to another state.\n",
    "+ **goal test**: some way of checking if a given state is the end state so that the search is over.\n",
    "+ **path cost function**: a way that tells us how expensive the solution is in terms of time, money, or any other resource relevant in the search problem.\n",
    "\n",
    "> **Definition: optimal solution**<br><br>A solution that has the lowest path cost among all solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the information about the search problem\n",
    "\n",
    "In a search process, data is often stored in a **node**, a data structure defined as:\n",
    "\n",
    "> **Definition: node**<br><br>A data structure that keeps track of<ul><li>a state</li><li>its parent node, through which the current node is generated</li><li>the action that was applied to the state of the parent to get to the current node</li><li>the path cost from the initial state to this node</li></ul>\n",
    "\n",
    "\n",
    "#### Approach\n",
    "\n",
    "Nodes are data structures, and therefore, they don't search, they just hold information. To actually search, we use the **frontier**, the mechanism that manages the nodes.\n",
    "\n",
    "> **Definition: frontier**<br><br>A data structure that keeps track of all the available actions from a given state that haven't been explored before.\n",
    "\n",
    "The frontier represents all of the states that we could explore next, but haven't yet explored or visited.\n",
    " \n",
    "Our first naive approach could be similar to the following:\n",
    "\n",
    "+ Start with a frontier that contains the initial state.\n",
    "+ Repeat:\n",
    "  + If the frontier is empty, then there is no solution.\n",
    "  + Remove a node from the frontier (this will be the node that will be considered next in our search problem).\n",
    "  + if the node removed contains goal state, return the solution, and we're done.\n",
    "  + Otherwise, expand node (i.e., find all of the neighbors of that node), add those resulting nodes to the frontier.\n",
    "\n",
    "\n",
    "What can go wrong on our naive solution:\n",
    "+ There might be a transition to the previous state (an arrow from A -> B and from B -> A), thus creating an infinite loop.\n",
    "\n",
    "    Note that this is a common scenario. For example, in the 15 puzzle, a tile can go to the left, and then to the right again.\n",
    "\n",
    "![Naive approach won't work](../images/ds_naive_search_wont_work.png)\n",
    "\n",
    "The solution is to keep track of what we've already explored.\n",
    "\n",
    "So the revised, improved approach would be:\n",
    "+ Start with a frontier with the node that contains the initial state.\n",
    "+ Start with an empty explored set that will keep track of the states we have already explored (not the nodes, but the states themselves!).\n",
    "+ Repeat:\n",
    "  + If the frontier is empty, then there is no solution.\n",
    "  + Remove a node from the frontier.\n",
    "  + if the node removed contains goal state, build the solution (path from the initial state to goal), return it, and we're done.\n",
    "  + Otherwise: add the node to the explored set.\n",
    "  + Expand node (i.e., find all the neighbors of the current node by examining the available actions from the current node), and add those resulting nodes to the frontier if:\n",
    "    + they aren't already in the frontier\n",
    "    + and they aren't already in the explored set\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| To reiterate:<ul><li>The frontier holds nodes; those we haven't explored yet.</li><li>The explored set hold the states (not the nodes) that we have already explored</li></ul>. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The removal of a node from the frontier should be dictated by a rule and not performed arbitrarily: either using a stack (last-in, first-out, which will result in a depth-first search), or a queue (first-in, first-out, which will result in a breadth-first search) can be used.\n",
    "\n",
    "> **Definition: depth-first search algorithm**<br><br>A search algorithm that always expands the deepest node in the frontier.\n",
    "\n",
    "> **Definition: breadth-first search algorithm**<br><br>A search algorithm that always expands the shallowest node in the frontier.\n",
    "\n",
    "There are some tradeoffs between DFS (depth-first search) and BFS (breadth-first search). \n",
    "\n",
    "The DFS exhaust each and every path to the end to see if it leads to a solution. As a result, this one might take more time to get to the solution as it chooses a particular path (e.g., when trying to find the solution to a maze) and sticks to it.\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| As long as we are dealing with a finite state space (e.g., it is not an infinite maze), DFS will always find a solution. |\n",
    "\n",
    "DFS however, will not necessarily return the optimal solution. It can provide a sub-optimal solution, when a better solution is available.\n",
    "\n",
    "![DFS providing a suboptimal solution](../images/ds_dfs_sub_optimal_solution.png)\n",
    "\n",
    "Contrarily, BFS explores all possible solutions from a given point, which might lead to a solution that takes up a lot of memory to find the solution, but will find the solution faster and will return the optimal solution.\n",
    "\n",
    "Breadth-first search will provide the optimal solution, although it might use more memory than the DFS approach, as it might need to explore in some cases more states than DFS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following snippet shows how the search algorithm looks in Python:\n",
    "\n",
    "```python\n",
    "    def solve(self):\n",
    "        \"\"\"Finds the solution, if one exists\"\"\"\n",
    "\n",
    "        # keep track of number of states explored\n",
    "        self.num_explored = 0\n",
    "\n",
    "        # Initialize frontier with the starting node\n",
    "        start = Node(state=self.start, parent_node=None, action=None, cost=0)\n",
    "        if self.search_mode == DEPTH_FIRST_SEARCH:\n",
    "            frontier = StackFrontier()\n",
    "        else:\n",
    "            frontier = QueueFrontier()\n",
    "        frontier.add(start)\n",
    "\n",
    "        # Initialize an empty explored set\n",
    "        self.explored = set()\n",
    "\n",
    "        # Repeat until solution found or no solution found\n",
    "        while True:\n",
    "\n",
    "            # If frontier is empty, no solution is available\n",
    "            if frontier.empty():\n",
    "                raise Exception(\"No solution found to the search problem\")\n",
    "\n",
    "            # Get a node from the frontier\n",
    "            node = frontier.remove()\n",
    "            self.num_explored += 1\n",
    "\n",
    "            # If node is the goal, then we have a solution\n",
    "            if node.state == self.goal:\n",
    "                actions = []\n",
    "                cells = []\n",
    "                while node.parent_node is not None:\n",
    "                    actions.append(node.action)\n",
    "                    cells.append(node.state)\n",
    "                    node = node.parent_node\n",
    "                actions.reverse()\n",
    "                cells.reverse()\n",
    "                self.solution = (actions, cells)\n",
    "                return\n",
    "\n",
    "            # If it's not a solution, mark node as explored\n",
    "            self.explored.add(node.state)\n",
    "\n",
    "            # Then, add neighbors to frontier, assuming cost of child node is cost of parent node + 1\n",
    "            for action, state in self.neighbors(node.state):\n",
    "                if not frontier.contains_state(state) and state not in self.explored:\n",
    "                    child = Node(state=state, parent_node=node, action=action, cost=node.cost + 1)\n",
    "                    frontier.add(child)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve BFS, we need to add a bit of human ingenuity into the algorithm, so that it does what a human would do. For example, instead of relying on a predefined sequence to choose what is the next node to explore, a human would choose the node that makes us closer to the goal (geographically).\n",
    "\n",
    "Note that this assumes that you know the coordinates of every node.\n",
    "\n",
    "> **Definition: uninformed search**<br><br>A search strategy that use no problem-specific knowledge.\n",
    "\n",
    "Pure DFS and BFS are uninformed search algorithms.\n",
    "\n",
    "> **Definition: informed search**<br><br>A search strategy that uses problem-specific knowledge.\n",
    "\n",
    "> **Definition: greedy best-first search**<br><br>An informed search algorithm that expands the node that is closest to the goal, as estimated by a heuristic function $ h(n) $, that takes the state as input. The heuristic function is estimating whether we're closer to the goal.\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| Greedy Best-First Search is often abbreviated as GBFS. |\n",
    "\n",
    "For the maze problem, the *Manhattan distance* which just tells us how many blocks we need to traverse to get from a given block to the goal is a good option. Using the *Manhattan distance* makes us relax the problem and ignore the goal. \n",
    "\n",
    "![Manhattan distance](../images/ds_manhattandistance.png)\n",
    "\n",
    "As a human, I'd rather be in position 'D' than positio 'C' when finding the solution to the maze, because 'D' is closer to the goal than 'C'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manhattan distance\n",
    "\n",
    "The Manhattan distance between any given state $ s $ and the goal state g, in which $ s = (s_{row}, s_{col}) $ as:\n",
    "$\n",
    "manhattan\\_distance = | s_{row} - goal_{row} | + | s_{col} - goal_{col} |\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *heuristic* isn't a guarantee of how many steps it is going to take, but rather, it is an attempt to estimate the cost of getting to the goal in a *\"relaxed\" problem*.\n",
    "\n",
    "For example, consider the image below:\n",
    "\n",
    "![GBFS mistake](../images/ds_gbfs_mistake.png)\n",
    "\n",
    "\n",
    "The heuristic will make us go up, when actually the other path will lead to better results.\n",
    "\n",
    "![GBFS mistake realization](../images/ds_gbfs_mistake_out.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBFS do not render the optimal solution either, as can be seen in the following picture:\n",
    "\n",
    "![GBFS is not perfect](../images/ds_gbfs_is_not_perfect.png)\n",
    "\n",
    "In that picture we can see that GBFS chose the longest path to the goal, because the heuristic told the agent to go up instead of left in the first fork."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimization to fix those type of the situations that happen using the gree best-first search is the A* (pronounced as a-star search:\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| Greedy means taking the best decision locally, without taking a look at surrounding factors. |\n",
    "\n",
    "\n",
    "> **Definition: A* (A star) search**<br><br>A search algorithm that expands node with lowest value of $ g(n) + h(n) $ where:<br>&nbsp;&nbsp;$ g(n) $ is the cost to reach node <br>&nbsp;&nbsp;$ h(n) $ is the estimated cost to goal\n",
    "\n",
    "See in the following picture how even when the agent initially chose the upper path at some point, after a few steps, it realized that it was wrong so it backtracked, and took the right path which led it to the best solution.\n",
    "\n",
    "![A* search in action](../images/ds_a_star.png)\n",
    "\n",
    "This algorithm is optimal under certain conditions:\n",
    "+ $ h(n) $ is admissible (never overestimates the true cost; i.e., it should render the true cost, or understimate how far we are from the goal)\n",
    "+ $ h(n) $ is consistent (for every node $ n $ and successor $ n' $ with step cost c, $ h(n) \\le h(n') + c $)\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| A* is not the ultimate search algorithm. There are variations of A* that take less memory to find a solution, and other algorithms that are suitable for other specific use cases. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adversarial search (1:12)\n",
    "\n",
    "Whereas, previously, we have discussed algorithms that need to find an answer to a question (what's the path to the exit of the maze), in **adversarial search** the algorithm faces an opponent that tries to achieve the opposite goal. This is often encountered in games, such as tic tac toe.\n",
    "\n",
    "There's an agent trying to win a game, while some other is trying to stop from winning the game.\n",
    "\n",
    "**Minimax** is an algorithm that works well with adversarial types of situations.\n",
    "\n",
    "First we assign a numerical value to each of the possible end goals.\n",
    "\n",
    "For example, in Tic-tac-toe game, \"O\" player winning can be -1, no player winning can be 0, and \"X\" player winning can be \"+1\".\n",
    "\n",
    "In this algorithm we try to:\n",
    "+ The X player: MAX(X) aims to maximize the score, for example, X player would prefer a no-player wins situation rather than a \"-1\" which means \"O\" player winning.\n",
    "+ The Y player: MIN(O) aims to minimize the score of the game, meaning it would rather have 0, meaning no player wins, rather than a \"+1\" which means, X player wins.\n",
    "\n",
    "\n",
    "> **Definition: Minimax**<br><br>A search algorithm that expands node with lowest value of $ g(n) + h(n) $ where:<br>&nbsp;&nbsp;$ g(n) $ is the cost to reach node<br>&nbsp;&nbsp;$ h(n) $ is the estimated cost to goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to codify this into an AI program we will need:\n",
    "\n",
    "+ $ S_0 $: initial state\n",
    "+ A function $ Player(s) $ that takes in a state and returns which player to move in state $ s $.\n",
    "+ A function $ Actions(s) $ that returns legal moves in state $ s $\n",
    "+ A function $ Result(s, a) $ that returns the state after action $ a $ has been taken in state $ s $.\n",
    "+ A function $ Terminal(s) $ to check whether state $ s $ is a terminal state\n",
    "+ A $ Utility(s) $ function that takes a state and give us a numerical value for a terminal state s, that is, the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following picture illustrates how the Minimax algorithm works.\n",
    "\n",
    "Remember that we have two players:\n",
    "+ one player is trying to maximize the score\n",
    "+ one player is trygin to minimize the score\n",
    "\n",
    "The player trying to maximize the score is depicted with a green triangle pointing up, the player trying to minimize the score is depicted with a red triangle pointing down.\n",
    "\n",
    "The diagram should be read bottom-up, with the player trying to minimize playing first:\n",
    "\n",
    "![Graphical Minimax](../images/ds_minimax.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the pseudocode will be:\n",
    "\n",
    "+ Given a state $ s $\n",
    "  + MAX picks action $ a $ in $ ACTIONS(s) $ that produces the highest value of $ MIN-VALUE(RESULT(s, a)) $\n",
    "  + MIN picks action $ a $ in $ ACTIONS(S) $ that produces the smallest value of $ MAX-VALUE(RESULT(s, a)) $\n",
    "\n",
    "Now, we need to turn our focus in the $ MAX-VALUE(s) $ and $ MIN-VALUE(s) $ functions:\n",
    "\n",
    "```\n",
    "function Max-Value(state):\n",
    "  if Terminal(state):\n",
    "    return Utility(state)\n",
    "  \n",
    "  v = -∞ # initial value\n",
    "  for action in Actions(state):\n",
    "    v = Max(v, Min-Value(Result(state, action))) # consider what the MIN player (my opponent) will do\n",
    "  return v\n",
    "```\n",
    "\n",
    "And for the $ MIN-VALUE(s) $ is the opposite:\n",
    "```\n",
    "function Min-Value(state):\n",
    "  if Terminal(state):\n",
    "    return Utility(state)\n",
    "  \n",
    "  v = ∞ # initial value\n",
    "  for action in Actions(state):\n",
    "    v = Min(v, Max-Value(Result(state, action))) # consider what the MAX player (my opponent) will do\n",
    "  return v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha-Beta Pruning\n",
    "\n",
    "It is an optimization on Minimax algorith. It consists in identifying a situation that would let me stop the recursive process sooner without exploring all of the nodes.\n",
    "\n",
    "![Minimax optimization](../images/ds_minimax_optimizations.png)\n",
    "\n",
    "This is called alpha-beta pruning. The alpha-beta references the two values you need to keep track of (the best you can do so far, the worst you can do so far) and the pruning comes from getting read of branches and subbranches.\n",
    "\n",
    "Alpha-beta pruning works OK for simple games, such as tic-tac-toe in which you have 255,168 possible games (calculate).\n",
    "\n",
    "However, in more complex games like chess you'll have total $ 10^{29000} $ possible chess games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth-Limited Minimax\n",
    "\n",
    "After a certain number of moves I will not consider additional moves.\n",
    "\n",
    "This requires the introduction of an *evaluation function*.\n",
    "\n",
    "\n",
    "> **Definition: evaluation function**<br><br>A function that estimates the expected utility of the game from a given state.\n",
    "\n",
    "The better the evaluation function is, the better the AI will be in solving the game.\n",
    "\n",
    "For example, a simple evaluation function for chess would be to calculate the number of pieces you have vs. the number of pieces your opponent has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Adversarial search shows up a lot:\n",
    "+ trying to find locations from one place to another\n",
    "+ how to take a decision that is rational\n",
    "+ how to play a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz\n",
    "\n",
    "##### Q1. Choose one:\n",
    "Between depth first search (DFS) and breadth first search (BFS), which will find a shorter path through a maze?\n",
    "\n",
    "- [ ] DFS will always find a shorter path than BFS\n",
    "- [X] BFS will always find a shorter path than DFS\n",
    "- [ ] DFS will sometimes, but not always, find a shorter path than BFS\n",
    "- [X] BFS will sometimes, but not always, find a shorter path than DFS\n",
    "- [ ] Both algorithms will always find paths of the same length\n",
    "\n",
    "The thing is that BFS will find the shortest path always, while DFS will sometimes find the shortest path. Thus, there will be cases in which DFS will find the same path as DFS, and therefore, the path discovered by BFS won't be shorter but equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2. Choose one:\n",
    "\n",
    "Consider the maze below, where grey cells indicate walls. A search algorithm was run on this maze, and found the yellow highlighted path from point A to B. In doing so, the red highlighted cells were the states explored but that did not lead to the goal.\n",
    "\n",
    "![Maze](../images/ds_quiz0_q2.png)\n",
    "\n",
    "Of the four search algorithms discussed in lecture (DFS, BFS, greedy best-first search with Manhattan distance heuristic, and A* search with Manhattan distance heuristic), which one (or multiple, if multiple are possible) could be the algorithm used?\n",
    "\n",
    "- [ ] Could only be A*\n",
    "- [ ] Could only be greedy best-first search\n",
    "- [ ] Could only be DFS\n",
    "- [ ] Could only be BFS\n",
    "- [ ] Could be either A* or greedy best first search\n",
    "- [ ] Could be either DFS or BFS\n",
    "- [ ] Could be any of the four algorithms\n",
    "- [ ] Could not be any of the four algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It cannot be BFS, as there are paths along the way to the solution, that hasn't been explored.\n",
    "\n",
    "It cannot be DFS either, as there are paths along the way that were not exhausted until completion.\n",
    "\n",
    "It can be either A* or GBFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3. Choose one:\n",
    "\n",
    "Why is depth-limited minimax sometimes preferable to minimax without a depth limit?\n",
    "\n",
    "- [ ] Depth-limited minimax can arrive at a decision more quickly because it explores fewer states\n",
    "- [ ] Depth-limited minimax will achieve the same output as minimax without a depth limit, but can sometimes use less memory\n",
    "- [ ] Depth-limited minimax can make a more optiomal decision by not exploring states known to be suboptimal\n",
    "- [ ] Depth-limited minimax is never preferable to minimax without a depth limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4. Choose one:\n",
    "\n",
    "The following question will ask you about the Minimax tree below, where the green up arrows indicate the MAX player and the red down arrows indicate the MIN player.\n",
    "\n",
    "The leaf nodes are each labelled with their value.\n",
    "\n",
    "What is the value of the root node?\n",
    "\n",
    "- [ ] 2\n",
    "- [ ] 3\n",
    "- [ ] 4\n",
    "- [ ] 5\n",
    "- [ ] 6\n",
    "- [ ] 7\n",
    "- [ ] 8\n",
    "- [ ] 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project 0 - Degrees of separation\n",
    "\n",
    "Write a program that determines how many \"degrees of separation\" apart two actors are.\n",
    "\n",
    "This would be the output of a run:\n",
    "```bash\n",
    "$ python degrees.py large\n",
    "Loading data...\n",
    "Name: Emma Watson\n",
    "Name: Jennifer Lawrence\n",
    "3 degrees of separation.\n",
    "1: Emma Watson and Brendan Gleeson starred in Harry Potter and the Order of the Phoenix\n",
    "2: Brendan Gleeson and Michael Fassbender starred in Trespass Against Us\n",
    "3: Michael Fassbender and Jennifer Lawrence starred in X-Men: First Class\n",
    "```\n",
    "\n",
    "##### Background\n",
    "\n",
    "According to the [Six Degrees of Kevin Bacon](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon) game, anyone in Hollywood film industry can be connected to Kevin Bacon within six steps, where each step consists of finding a fil that two actors both starred in.\n",
    "\n",
    "In this problem, we're interested in finding the shortest path between any two actors by choosing a sequence of movies that connects them.\n",
    "\n",
    "For example, the shortest path between Jennifer Lawrence and Tom Hanks is 2, as Jennifer Lawrence worked with Kevin Bacon in \"X-Men: First Class\", and Kevin Bacon worked with Tom Hanks in \"Apollo 13\".\n",
    "\n",
    "This problem can be framed as a search problem: our states are people (actors), and the actions are movies, which take us from one state (actor) to another state (actor). The initial and goal states are stated when choose the actors that we want to link. By using a breadth-first search, we can find the shortest path from one actor to another.\n",
    "\n",
    "##### Understanding\n",
    "\n",
    "The distribution code contains two sets of CSV data files: one set in the `large/` dir and another one in the `small/` dir. Each contains files with the same names and structure but with less content for testing and experimentation.\n",
    "\n",
    "Each dataset consists of three CSVs. The `people.csv` features the actors, `movies.csv` the movies, and `stars.csv` the relationships between the movies and the actors.\n",
    "\n",
    "Using this files, you can easily check that Kevin Bacon starred in the movie \"A Few Good Men\".\n",
    "\n",
    "The file `degrees.py` contains several data structures at the top to store information from the CSV files. The `names` dictionary is way to look up a person by their name &mdash; that is, it maps names to a set of corresponding ids (as multiple actors might have the same name).\n",
    "\n",
    "The `people` dictionary maps each person's id to with values for the person's `name`, `birth` (for birth year) and the set of all the `movies` they have starred in. Finally, the `movies` dictionary maps each movie's id to another dictionary with values for that movie `title`, release `year` , and the set of all the movie's `stars`. The `load_data()` function loads data from the CSV files into these data structures.\n",
    "\n",
    "The `main()` function in this program first loads data into memory (the directory from which the dta is loaded can be specified by a command-line argument). Then, the function prompts the user to type in two names.\n",
    "\n",
    "The `person_id_for_name()` retrieves the id for any person (and handles prompting the user to clarify, in the event that multiple people have the same name). The function then calls `shortest_path()` function to compute the shortest path between the two people, and prints out the path.\n",
    "\n",
    "##### Specification\n",
    "\n",
    "| NOTE: |\n",
    "| :---- |\n",
    "| You should not be importing modules other than those explicitly allowed, or modify functions other than as permitted. |\n",
    "\n",
    "Complete the implementation of the `shortest_path()` function so that it returns the shortest path from the person with id `source` to the person with the id `target`.\n",
    "+ Assuming there is a path from the `source` to the `target`, your function should return a list where each list item is the next `(movie_id, person_id)` pair in the path from the source to the target. Each pair should be a tuple of two strings.\n",
    "\n",
    "    For example, if the result of the function is `[(1, 2), (3,4)]` that would mean that `source` starred in movie with id 1 with person 2, and person 2 starred in movie 3 with person 4, and person 4 is the `target`.\n",
    "\n",
    "+ If there are multiple paths of minimum length from the source to the target, the function can return any of them.\n",
    "\n",
    "+ If there is no possible path between two actors, your function should return `None`.\n",
    "\n",
    "+ You may call the funcion `neighbors_for_person()`, which accepts a person's id as input and returns a set of `(movie_id, person_id)` pairs for all people who starred in a movie with a given person.\n",
    "\n",
    "+ You cannot modify anything else other than the `shortest_path()` function, but you can write additional functions and/or import other Python standard library modules.\n",
    "\n",
    "+ There's an `util.py` that contains implementations for `Node`, `StackFrontier`, and `QueueFrontier` which you can use and modify.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:36:00 - Alpha-Beta pruning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a2c4b191d1ae843dde5cb5f4d1f62fa892f6b79b0f9392a84691e890e33c5a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
